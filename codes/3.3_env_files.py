import argparse
import ast
import os
import re
from typing import Dict, Iterable, List, Set


STDLIB_FALLBACK: Set[str] = {
    "abc",
    "argparse",
    "asyncio",
    "collections",
    "contextlib",
    "copy",
    "csv",
    "dataclasses",
    "datetime",
    "functools",
    "glob",
    "hashlib",
    "heapq",
    "importlib",
    "inspect",
    "io",
    "itertools",
    "json",
    "logging",
    "math",
    "multiprocessing",
    "os",
    "pathlib",
    "pickle",
    "platform",
    "queue",
    "random",
    "re",
    "shutil",
    "signal",
    "socket",
    "sqlite3",
    "statistics",
    "string",
    "subprocess",
    "sys",
    "tempfile",
    "threading",
    "time",
    "traceback",
    "typing",
    "unittest",
    "uuid",
    "warnings",
    "xml",
    "zipfile",
}


MODULE_TO_PACKAGE: Dict[str, str] = {
    "cv2": "opencv-python",
    "PIL": "Pillow",
    "yaml": "pyyaml",
    "sklearn": "scikit-learn",
    "sksurv": "scikit-survival",
    "lightning": "lightning",
    "pytorch_lightning": "pytorch-lightning",
    "torchvision": "torchvision",
    "torchaudio": "torchaudio",
    "open_clip": "open-clip-torch",
    "openslide": "openslide-python",
    "segmentation_models_pytorch": "segmentation-models-pytorch",
    "transformers": "transformers",
    "tokenizers": "tokenizers",
    "datasets": "datasets",
    "sentencepiece": "sentencepiece",
    "omegaconf": "omegaconf",
    "hydra": "hydra-core",
    "einops": "einops",
    "timm": "timm",
    "pyarrow": "pyarrow",
    "h5py": "h5py",
    "pandas": "pandas",
    "numpy": "numpy",
    "scipy": "scipy",
    "matplotlib": "matplotlib",
    "seaborn": "seaborn",
    "tqdm": "tqdm",
    "requests": "requests",
    "joblib": "joblib",
    "click": "click",
    "typer": "typer",
    "pytest": "pytest",
    "torch": "torch",
}


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser()
    parser.add_argument("--output_repo_dir", type=str, required=True)
    parser.add_argument("--python_version", type=str, default="3.10")
    return parser.parse_args()


def get_stdlib_modules() -> Set[str]:
    if hasattr(__import__("sys"), "stdlib_module_names"):
        # pyright: ignore[reportAttributeAccessIssue]
        return set(__import__("sys").stdlib_module_names)  # type: ignore[attr-defined]
    return STDLIB_FALLBACK


def iter_python_files(root_dir: str) -> Iterable[str]:
    for root, _, files in os.walk(root_dir):
        if "__pycache__" in root:
            continue
        for filename in files:
            if filename.endswith(".py"):
                yield os.path.join(root, filename)


def extract_top_modules_from_source(source: str) -> Set[str]:
    modules: Set[str] = set()
    try:
        tree = ast.parse(source)
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    modules.add(alias.name.split(".")[0])
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    modules.add(node.module.split(".")[0])
    except SyntaxError:
        # Fallback parser for partially malformed files.
        for line in source.splitlines():
            line = line.strip()
            if line.startswith("import "):
                mod = line[len("import ") :].split(" as ")[0].split(",")[0].strip()
                if mod:
                    modules.add(mod.split(".")[0])
            elif line.startswith("from "):
                m = re.match(r"from\s+([a-zA-Z0-9_\.]+)\s+import", line)
                if m:
                    modules.add(m.group(1).split(".")[0])
    return modules


def collect_repo_modules(repo_dir: str) -> Set[str]:
    modules: Set[str] = set()
    for py_file in iter_python_files(repo_dir):
        with open(py_file, "r", encoding="utf-8", errors="ignore") as f:
            modules |= extract_top_modules_from_source(f.read())
    return modules


def to_requirements(modules: Set[str], stdlib_modules: Set[str], include_pytest: bool) -> List[str]:
    requirements: Set[str] = set()
    for module in modules:
        if module in stdlib_modules:
            continue
        if module in {"src", "configs", "tests", "__future__"}:
            continue
        package = MODULE_TO_PACKAGE.get(module, module)
        requirements.add(package)
    if include_pytest:
        requirements.add("pytest")
    return sorted(requirements)


def write_requirements(repo_dir: str, requirements: List[str]) -> str:
    path = os.path.join(repo_dir, "requirements.txt")
    lines = ["# Auto-generated by codes/3.3_env_files.py"]
    lines.extend(requirements)
    with open(path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines) + "\n")
    return path


def write_environment_yaml(repo_dir: str, python_version: str) -> str:
    path = os.path.join(repo_dir, "environment.yml")
    content = (
        "name: paper2code-env\n"
        "channels:\n"
        "  - conda-forge\n"
        "  - pytorch\n"
        "dependencies:\n"
        f"  - python={python_version}\n"
        "  - pip\n"
        "  - pip:\n"
        "    - -r requirements.txt\n"
    )
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)
    return path


def main() -> None:
    args = parse_args()
    repo_dir = os.path.realpath(args.output_repo_dir)
    if not os.path.isdir(repo_dir):
        raise FileNotFoundError(f"output_repo_dir not found: {repo_dir}")

    stdlib_modules = get_stdlib_modules()
    modules = collect_repo_modules(repo_dir)
    include_pytest = os.path.isdir(os.path.join(repo_dir, "tests"))
    reqs = to_requirements(modules, stdlib_modules, include_pytest)

    req_path = write_requirements(repo_dir, reqs)
    env_path = write_environment_yaml(repo_dir, args.python_version)

    print(f"[SAVED] {req_path}")
    print(f"[SAVED] {env_path}")


if __name__ == "__main__":
    main()
